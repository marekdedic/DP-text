
@article{chen_miles:_2006,
	title = {{MILES}: Multiple-Instance Learning via Embedded Instance Selection},
	volume = {28},
	issn = {0162-8828},
	doi = {10.1109/TPAMI.2006.248},
	shorttitle = {{MILES}},
	abstract = {Multiple-instance problems arise from the situations where training class labels are attached to sets of samples (named bags), instead of individual samples within each bag (called instances). Most previous multiple-instance learning ({MIL}) algorithms are developed based on the assumption that a bag is positive if and only if at least one of its instances is positive. Although the assumption works well in a drug activity prediction problem, it is rather restrictive for other applications, especially those in the computer vision area. We propose a learning method, {MILES} (multiple-instance learning via embedded instance selection), which converts the multiple-instance learning problem to a standard supervised learning problem that does not impose the assumption relating instance labels to bag labels. {MILES} maps each bag into a feature space defined by the instances in the training bags via an instance similarity measure. This feature mapping often provides a large number of redundant or irrelevant features. Hence, 1-norm {SVM} is applied to select important features as well as construct classifiers simultaneously. We have performed extensive experiments. In comparison with other methods, {MILES} demonstrates competitive classification accuracy, high computation efficiency, and robustness to labeling uncertainty},
	pages = {1931--1947},
	number = {12},
	journaltitle = {{IEEE} Transactions on Pattern Analysis and Machine Intelligence},
	author = {Chen, Yixin and Bi, Jinbo and Wang, J. Z.},
	date = {2006-12},
	keywords = {1-norm support vector machine, Algorithms, Application software, Artificial Intelligence, classification accuracy, computer vision, drug activity prediction, drug activity prediction., Drugs, embedded instance selection, feature extraction, feature mapping, feature subset selection, image categorization, Image Enhancement, Image Interpretation, Computer-Assisted, Imaging, Three-Dimensional, Information Storage and Retrieval, Labeling, labeling uncertainty, learning (artificial intelligence), Learning systems, {MILES}, Multiple-instance learning, multiple-instance learning algorithms, object recognition, pattern classification, Reproducibility of Results, Robustness, Sensitivity and Specificity, supervised learning, support vector machine, Support vector machine classification, support vector machines, Uncertainty}
}

@article{dietterich_solving_1997,
	title = {Solving the multiple instance problem with axis-parallel rectangles},
	volume = {89},
	issn = {0004-3702},
	url = {http://www.sciencedirect.com/science/article/pii/S0004370296000343},
	doi = {10.1016/S0004-3702(96)00034-3},
	abstract = {The multiple instance problem arises in tasks where the training examples are ambiguous: a single example object may have many alternative feature vectors (instances) that describe it, and yet only one of those feature vectors may be responsible for the observed classification of the object. This paper describes and compares three kinds of algorithms that learn axis-parallel rectangles to solve the multiple instance problem. Algorithms that ignore the multiple instance problem perform very poorly. An algorithm that directly confronts the multiple instance problem (by attempting to identify which feature vectors are responsible for the observed classifications) performs best, giving 89\% correct predictions on a musk odor prediction task. The paper also illustrates the use of artificial data to debug and compare these algorithms.},
	pages = {31--71},
	number = {1},
	journaltitle = {Artificial Intelligence},
	shortjournal = {Artificial Intelligence},
	author = {Dietterich, Thomas G. and Lathrop, Richard H. and Lozano-Pérez, Tomás},
	urldate = {2017-05-31},
	date = {1997-01-01},
	keywords = {Drug design, Machine learning, Structure-activity relationships}
}

@inproceedings{kandemir_empowering_2014,
	location = {Cham},
	title = {Empowering Multiple Instance Histopathology Cancer Diagnosis by Cell Graphs},
	isbn = {978-3-319-10470-6},
	doi = {10.1007/978-3-319-10470-6_29},
	series = {Lecture Notes in Computer Science},
	abstract = {We introduce a probabilistic classifier that combines multiple instance learning and relational learning. While multiple instance learning allows automated cancer diagnosis from only image-level annotations, relational learning allows exploiting changes in cell formations due to cancer. Our method extends Gaussian process multiple instance learning with a relational likelihood that brings improved diagnostic performance on two tissue microarray data sets (breast and Barrett’s cancer) when similarity of cell layouts in different tissue regions is used as relational side information.},
	pages = {228--235},
	booktitle = {Medical Image Computing and Computer-Assisted Intervention – {MICCAI} 2014},
	publisher = {Springer International Publishing},
	author = {Kandemir, Melih and Zhang, Chong and Hamprecht, Fred A.},
	editor = {Golland, Polina and Hata, Nobuhiko and Barillot, Christian and Hornegger, Joachim and Howe, Robert},
	date = {2014},
	langid = {english},
	keywords = {Local Binary Pattern, Marginal Likelihood, Multiple Instance, Receiver Operating Characteristic Curve, Side Information},
	file = {Springer Full Text PDF:/home/cisco/Zotero/storage/Q7PDTMBN/Kandemir et al. - 2014 - Empowering Multiple Instance Histopathology Cancer.pdf:application/pdf}
}

@article{zhou_multi-instance_2005,
	title = {Multi-Instance Learning Based Web Mining},
	volume = {22},
	issn = {1573-7497},
	url = {https://doi.org/10.1007/s10489-005-5602-z},
	doi = {10.1007/s10489-005-5602-z},
	abstract = {In multi-instance learning, the training set comprises labeled bags that are composed of unlabeled instances, and the task is to predict the labels of unseen bags. In this paper, a web mining problem, i.e. web index recommendation, is investigated from a multi-instance view. In detail, each web index page is regarded as a bag, while each of its linked pages is regarded as an instance. A user favoring an index page means that he or she is interested in at least one page linked by the index. Based on the browsing history of the user, recommendation could be provided for unseen index pages. An algorithm named Fretcit-{kNN}, which employs the Minimal Hausdorff distance between frequent term sets and utilizes both the references and citers of an unseen bag in determining its label, is proposed to solve the problem. Experiments show that in average the recommendation accuracy of Fretcit-{kNN} is 81.0\% with 71.7\% recall and 70.9\% precision, which is significantly better than the best algorithm that does not consider the specific characteristics of multi-instance learning, whose performance is 76.3\% accuracy with 63.4\% recall and 66.1\% precision.},
	pages = {135--147},
	number = {2},
	journaltitle = {Applied Intelligence},
	shortjournal = {Appl Intell},
	author = {Zhou, Zhi-Hua and Jiang, Kai and Li, Ming},
	urldate = {2020-01-01},
	date = {2005-03-01},
	langid = {english},
	keywords = {data mining, machine learning, multi-instance learning, text categorization, web index recommendation, web mining}
}

@article{zhou_multi-instance_2008,
	title = {Multi-Instance Learning by Treating Instances As Non-I.I.D. Samples},
	doi = {10.1145/1553374.1553534},
	abstract = {Multi-instance learning attempts to learn from a training set consisting of labeled bags each containing many unlabeled instances. Previous studies typically treat the instances in the bags as independently and identically distributed. However, the instances in a bag are rarely independent, and therefore a better performance can be expected if the instances are treated in an non-i.i.d. way that exploits the relations among instances. In this paper, we propose a simple yet effective multi-instance learning method, which regards each bag as a graph and uses a specific kernel to distinguish the graphs by considering the features of the nodes as well as the features of the edges that convey some relations among instances. The effectiveness of the proposed method is validated by experiments. Comment: {ICML}, 2009},
	journaltitle = {Proceedings of the 26th International Conference On Machine Learning, {ICML} 2009},
	shortjournal = {Proceedings of the 26th International Conference On Machine Learning, {ICML} 2009},
	author = {Zhou, Zhi-Hua and Sun, Yu-Yin and Li, Yu-Feng},
	date = {2008-07-12}
}

@inproceedings{srinivasan_comparing_1995,
	title = {Comparing the use of background knowledge by inductive logic programming systems},
	author = {Srinivasan, A. and Muggleton, Stephen and King, Robert},
	date = {1995},
	keywords = {Inductive logic programming}
}

@article{briggs_rank-loss_2012,
	title = {Rank-loss support instance machines for {MIML} instance annotation},
	doi = {10.1145/2339530.2339616},
	abstract = {Multi-instance multi-label learning ({MIML}) is a framework for supervised classification where the objects to be classified are bags of instances associated with multiple labels. For example, an image can be represented as a bag of segments and associated with a list of objects it contains. Prior work on {MIML} has focused on predicting label sets for previously unseen bags. We instead consider the problem of predicting instance labels while learning from data labeled only at the bag level. We propose Rank-Loss Support Instance Machines, which optimize a regularized rank-loss objective and can be instantiated with different aggregation models connecting instance-level predictions with bag-level predictions. The aggregation models that we consider are equivalent to defining a "support instance" for each bag, which allows efficient optimization of the rank-loss objective using primal sub-gradient descent. Experiments on artificial and real-world datasets show that the proposed methods achieve higher accuracy than other loss functions used in prior work, e.g., Hamming loss, and recent work in ambiguous label classification.},
	journaltitle = {Proceedings of the {ACM} {SIGKDD} International Conference on Knowledge Discovery and Data Mining},
	shortjournal = {Proceedings of the {ACM} {SIGKDD} International Conference on Knowledge Discovery and Data Mining},
	author = {Briggs, Forrest and Fern, Xiaoli and Raich, Raviv},
	date = {2012-08-12},
	file = {Full Text PDF:/home/cisco/Zotero/storage/XM4XPD5R/Briggs et al. - 2012 - Rank-loss support instance machines for MIML insta.pdf:application/pdf}
}

@article{ray_learning_2005,
	title = {Learning Statistical Models for Annotating Proteins with Function Information using Biomedical Text},
	volume = {6},
	issn = {1471-2105},
	url = {https://doi.org/10.1186/1471-2105-6-S1-S18},
	doi = {10.1186/1471-2105-6-S1-S18},
	abstract = {The {BioCreative} text mining evaluation investigated the application of text mining methods to the task of automatically extracting information from text in biomedical research articles. We participated in Task 2 of the evaluation. For this task, we built a system to automatically annotate a given protein with codes from the Gene Ontology ({GO}) using the text of an article from the biomedical literature as evidence.},
	pages = {S18},
	number = {1},
	journaltitle = {{BMC} Bioinformatics},
	shortjournal = {{BMC} Bioinformatics},
	author = {Ray, Soumya and Craven, Mark},
	urldate = {2020-01-01},
	date = {2005-05-24},
	file = {Full Text:/home/cisco/Zotero/storage/FUPK8UEP/Ray and Craven - 2005 - Learning Statistical Models for Annotating Protein.pdf:application/pdf;Snapshot:/home/cisco/Zotero/storage/VL88HZLW/1471-2105-6-S1-S18.html:text/html}
}

@inproceedings{ray_supervised_2005,
	title = {Supervised versus multiple instance learning: An empirical comparison},
	doi = {10.1145/1102351.1102439},
	shorttitle = {Supervised versus multiple instance learning},
	abstract = {We empirically study the relationship be- tween supervised and multiple instance ({MI}) learning. Algorithms to learn various con- cepts have been adapted to the {MI} represen- tation. However, it is also known that con- cepts that are {PAC}-learnable with one-sided noise can be learned from {MI} data. A rel- evant question then is: how well do super- vised learners do on {MI} data? We attempt to answer this question by looking at a cross section of {MI} data sets from various domains coupled with a number of learning algorithms including Diverse Density, Logistic Regres- sion, nonlinear Support Vector Machines and {FOIL}. We consider a supervised and {MI} ver- sion of each learner. Several interesting con- clusions emerge from our work: (1) no {MI} al- gorithm is superior across all tested domains, (2) some {MI} algorithms are consistently su- perior to their supervised counterparts, (3) using high false-positive costs can improve a supervised learner's performance in {MI} do- mains, and (4) in several domains, a super- vised algorithm is superior to any {MI} algo- rithm we tested.},
	eventtitle = {{ICML} 2005 - Proceedings of the 22nd International Conference on Machine Learning},
	pages = {697--704},
	author = {Ray, Soumya and Craven, Mark},
	date = {2005-01-01}
}

@article{andrews_support_2002,
	title = {Support Vector Machines for Multiple-Instance Learning},
	volume = {15},
	abstract = {This paper presents two new formulations of multiple-instance learning as a maximum margin problem. The proposed extensions of the Support Vector Machine ({SVM}) learning approach lead to mixed integer quadratic programs that can be solved heuristically. Our generalization of {SVMs} makes a state-of-the-art classication technique, including non-linear classication via kernels, available to an area that up to now has been largely dominated by special purpose methods. We present experimental results on a pharma- ceutical data set and on applications in automated image indexing and document categorization.},
	pages = {561--568},
	journaltitle = {Advances in Neural Information Processing Systems},
	shortjournal = {Advances in Neural Information Processing Systems},
	author = {Andrews, Stuart and Tsochantaridis, Ioannis and Hofmann, Thomas},
	date = {2002-01-01},
	file = {Full Text PDF:/home/cisco/Zotero/storage/6H8Z43A4/Andrews et al. - 2002 - Support Vector Machines for Multiple-Instance Lear.pdf:application/pdf}
}