\chapter*{Introduction}
\addcontentsline{toc}{chapter}{Introduction}

Clustering is a prime example of a problem typically associated with unsupervised learning. One of the key design choices when using any clustering algorithm is to choose the right distance metric. Traditionally, one of the standard distance metrics such as the Euclidean, Manhattan or Mahalanobis distance would be used, using the designer's knowledge of the domain. For complex tasks, however, it is difficult to design a metric that is well-suited to the problem at hand. One of the possible solutions to this problem is using distance metric learning, that is using machine learning to construct a distance metric under which the desired clustering can be done easily. This automates the process of creating a problem-specific metric.

Multi-instance learning is a well-known approach to supervised machine learning on structured data. Multi-instance learning alleviates the need for having a label for each instance in the training set, instead relying on learning how to represent whole bags of instances. The feature extractor and the classifier are then trained in an end-to-end fashion. This has the advantage of being able to exploit the inherent structure of the data when designing the machine learning model.

In this work, clustering and multi-instance learning meet. While there have been previous attempts at multi-instance clustering, they have utilized the so-called bag-space paradigm, which is prohibitively computationally expensive for large datasets. Instead, an approach based on the so-called embedded-space paradigm was chosen for this work, as this approach offers a mix of high performance and the ability to construct complex hierarchical models tailored to the specific domain or application. For this approach, there exists no known prior art. In order to fill this gap and to offer a comparison, three different methods will be presented, experimentally evaluated and compared. The most promising of these three methods falls into the category of unsupervised learning, for which there is no need for labelled training data, which would make the method applicable to a broad set of problems.

To utilize and evaluate the proposed method, an industry application was selected -- network security. The problem of clustering and classifying network traffic is well known. Specifically, the problem of clustering second-level domains based on the activity clients are exhibiting towards them is tackled. Even an experienced network analyst can only investigate a limited amount of domains and having a clustering on the space of domains would allow them to only investigate a few of the domains in a cluster and then being able to label any current or future domain falling in the cluster as either legitimate or malicious. Moreover, with the recent spread of encrypted traffic over the HTTPS protocol, and the gradual roll-out of encryption to core protocols such as HTTP/3 (formerly known as QUIC) and Encrypted SNI, the amount of information available to the analyst is shrinking. If this work is successful, it could be in the future extended to cover the problem of classifying partially or fully encrypted network traffic.

The work is structured as follows: Chapter \ref{chap:MIL} introduces multi-instance learning, presents two formalisms used to mathematically describe it, presents and compares the three main paradigms used for multi-instance learning and provides a survey of the \textit{state of the art} with respect to multi-instance learning. Chapter \ref{chap:clustering} presents clustering as a machine learning task, presents its application to multi-instance learning and provides metrics for evaluating the performance of the proposed methods. Chapter \ref{chap:clustering-metric} is the core of this work. Three methods for multi-instance clustering are presented, each building on an original method in other domains of machine learning. The three methods are explained and theoretically compared. Chapter \ref{chap:toy-dataset} compares the methods experimentally on publicly available dataset. The author of this work considers it important to provide a replicable experiment which evaluates the methods in a way that is not constrained by the unavailability of proprietary datasets. Finally, chapter \ref{chap:cisco-dataset} evaluates the three methods on a corporate dataset of network traffic.
