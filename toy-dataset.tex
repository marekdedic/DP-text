\chapter{Evaluation on publicly available datasets}\label{chap:toy-dataset}

The three loss functions presented in chapter \ref{chap:clustering-metric} were  experimentally evaluated on publicly available datasets.

\section{Used datasets}

The evaluation was done on a set of 20 datasets. These are, in alphabetical order:
\begin{enumerate}
  \item The "BrownCreeper" and "WinterWren" datasets. See \cite{briggs_rank-loss_2012}. A dataset of bird songs where each bag represents a recording of one or multiple birds. Originally a 13-class dataset, converted to binary classification datasets by selecting a target class.
  \item The "CorelAfrican" and "CorelBeach" datasets. See \cite{chen_miles:_2006}. A dataset of object images where each bag is an image, consisting of segments described by \( 4 \times 4 \) patch features. Originally a 20-class dataset, converted to binary classification datasets by selecting a target class.
  \item The "Elephant", "Fox" and "Tiger" datasets. See \cite{andrews_support_2002}. A dataset of animal images where each bag is an image, consisting of segments. Originally a multi-class dataset (also with animals other that the 3), converted to binary classification datasets by selecting a target class.
  \item The "Musk1" and "Musk2" datasets. See \cite{dietterich_solving_1997}. A dataset of molecules where each bag is a set of the different shapes the molecule can fold into (so-called \textit{conformers}). The goal is to predict whether a molecule has a musky smell or not. If at least one of the conformers of a molecule can cause it to smell musky, the molecule is positive.
  \item The "Mutagenesis1" and "Mutagenesis2" datasets. See \cite{srinivasan_comparing_1995}. A dataset consisting of a drug activity prediction problem. There is an easy ("Mutagenesis1") and a hard ("Mutagenesis2") version.
  \item The "Newsgroups1", "Newsgroups2" and "Newsgroups3" datasets. See \cite{zhou_multi-instance_2008}. A text categorization dataset where each bag is a collection of posts from different newsgroups. A positive bag for a class is designed to contain 3\% of posts from the target class and 97\% randomly sampled from the other categories. Originally a 20-class dataset, converted to binary classification datasets by selecting a target class.
  \item The "Protein" dataset. See \cite{ray_learning_2005} and \cite{ray_supervised_2005}. A dataset consisting of protein annotations making it a text categorization problem. The task is to decide whether a given pair should be annotated by a Gene Ontology (GO) code.
  \item The "UCSBBreastCancer" dataset. See \cite{kandemir_empowering_2014}. A dataset consisting of 38 TMA image excerpts from breast cancer patients where each bag represents an image excerpt consisting of image patches. The goal is to predict whether the cancer is benign or malignant.
  \item The "Web1", "Web2", "Web3" and "Web4" datasets. See \cite{zhou_multi-instance_2005}. A dataset of webpages as ranked by 4 different users based on their being interesting. Each bag represents a webpage with instances being the links on the webpage.
\end{enumerate}

All the datasets as used were made public in \cite{dedic_mildatasetsjl_2019}.

\section{Used models}

The models for evaluation were implemented in the Julia programming language (see \cite{bezanson_julia:_2017}) using the Flux.jl framework for machine learning (see \cite{innes_flux:_2018}) and the Mill.jl framework for multi-instance learning (see \cite{pevny_milljl_2019}).

The embedding \( \phi \) was realised by a MIL neural network consisting of 2 per-instance layers of 30 neurons, followed by aggregation formed by concatenating element-wise mean and element-wise maximum of all instances in a bag, followed by 2 per-bag layers of 30 neurons. All the neurons used the ReLU activation function (see \cite{hahnloser_digital_2000}). Layer weights were initialized using Glorot initialization (see \cite{glorot_understanding_2010}), bias vectors were initialized to zeros. ADAM (see \cite{kingma_adam:_2014}) was used as the optimization method.

For each of the datasets, 80\% of bags was randomly chosen as the training data, with the rest being testing data. The models were trained using 100 mini-batches of size 50.

\section{Mean model}

In order to provide some baseline against which the models could be compared (as there is no prior art for this problem), a non-machine-learning model was introduced. This model implements the embedding \( \phi \) as an element-wise mean of all instances of a bag.

\section{Method hyper-parameter selection}

Some of the three proposed clustering-losses have some hyper-parameters which need to be tuned. \( L_\mathrm{CPC} \) has no hyper-parameters, \( L_\mathrm{triplet} \) has a single hyper-parameter \( c \), and \( L_\mathrm{magnet} \) has three hyper-parameters, \( K \), \( \alpha \) and the cluster index update frequency. For \( L_\mathrm{triplet} \) and \( L_\mathrm{magnet} \), a range of values was tried for each hyper-parameter in order to select the best configuration for each. The testing was done on the "Musk2" dataset, as it is sufficiently hard and simultaneously the best-known industry standard dataset for MIL.

\subsection{Triplet loss}
For \( L_\mathrm{triplet} \), the values \( c \in \left\{ 0.01, 0.1, 1, 10, 100 \right\} \) have been tested. Figure \ref{fig:triplet-gridsearch-ratio} shows the values of \( \mathrm{ratio} \left( \cdot \right) \) (see section \ref{sec:clustering-metrics}) for the different hyper-parameter values, figure \ref{fig:triplet-gridsearch-accuracy} shows the accuracy of a kNN classifier built on the embedding.

\begin{figure}[h]
  \centering
  \includegraphics[width=0.9\textwidth]{images/triplet-gridsearch/ratio/triplet-gridsearch-ratio.pdf}
  \caption{The value of \( \mathrm{ratio} \left( \cdot \right) \) over the learning period.}\label{fig:triplet-gridsearch-ratio}
\end{figure}

\begin{figure}[h]
  \centering
  \includegraphics[width=0.9\textwidth]{images/triplet-gridsearch/accuracy/triplet-gridsearch-accuracy.pdf}
  \caption{The accuracy of a kNN classifier built on the embedding over the learning period.}\label{fig:triplet-gridsearch-accuracy}
\end{figure}

As can be seen from the figures, for low values of \( c \), the performance is not good and, more importantly, isn't increasing over the learning period. In the end, the value \( c = 1 \) has been selected as it offers good performance and some of the higher values show some instability in the learning process.
